********** Time spent on model generation (gpt-4o-mini): 1054.79ms **********
Report generation error: Error: 400 This model's maximum context length is 128000 tokens. However, your messages resulted in 132373 tokens. Please reduce the length of the messages.
